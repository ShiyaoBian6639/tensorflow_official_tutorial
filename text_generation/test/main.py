import tensorflow as tf
from text_generation.model.encoder import Encoder
from text_generation.model.attention import BahdanauAttention
from text_generation.model.decoder import Decoder, DecoderInput
from text_generation.test.setup import embedding_dim, units, example_target_batch, example_input_batch, \
    input_text_processor, output_text_processor

"""
encoder layer
"""
# Convert the input text to tokens.
example_tokens = input_text_processor(example_input_batch)  # batch_size * seq_len

# Encode the input sequence.
encoder = Encoder(input_text_processor.vocabulary_size(),
                  embedding_dim, units)
example_enc_output, example_enc_state = encoder(example_tokens)
"""
encoder input dimensions: batch_size * seq_len

encoder output dimensions
1. example_enc_output: batch_size * seq_len * gru_units
2. example_enc_state: batch_size * gru_units
"""

print(f'Input batch, shape (batch): {example_input_batch.shape}')
print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')
print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')
print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')
"""
attention layer takes 3 inputs:
1. query: generated by decoder layer
2. value: output of encoder layer
3. mask
"""
attention_layer = BahdanauAttention(units)
# Later, the decoder will generate this attention query
example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])
# Attend to the encoded tokens
context_vector, attention_weights = attention_layer(
    query=example_attention_query,
    value=example_enc_output,
    mask=(example_tokens != 0))
"""
decoder takes 4 inputs:
1. new_token: the last token generated. Initialize the decoder with '[start]' token
2. enc_output: encoder output generated by encoder
3. mask: A boolean tensor indicating where token != 0
4. state: The previous state output from decoder
"""
decoder = Decoder(output_text_processor.vocabulary_size(), embedding_dim, units)
# Convert the target sequence, and collect the "[START]" tokens
example_output_tokens = output_text_processor(example_target_batch)

start_index = output_text_processor.get_vocabulary().index('[START]')
first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])

# Run the decoder
dec_result, dec_state = decoder(
    inputs=DecoderInput(new_tokens=first_token,
                        enc_output=example_enc_output,
                        mask=(example_tokens != 0)),
    state=example_enc_state
)
